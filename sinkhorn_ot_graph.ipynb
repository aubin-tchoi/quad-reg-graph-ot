{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU",
  "gpuClass": "standard"
 },
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Sinkhorn algorithm for Optimal Transport on Graphs"
   ],
   "metadata": {
    "id": "BQhSU5uhTbYt"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "This notebook does not import anything from the main project, it is meant to be imported and run in Google Colab if you do not have access to a GPU locally."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Imports"
   ],
   "metadata": {
    "id": "Hq-52F3UJAks"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# There are some incompatibilities between certain scipy and networkx versions\n",
    "%pip install --upgrade scipy networkx\n",
    "%pip install scipy==1.8.1"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 373
    },
    "id": "E4S1649fHBtk",
    "outputId": "8fa64ceb-a55e-446a-d20c-3f2242d5637d",
    "pycharm": {
     "is_executing": true
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import json\n",
    "import random\n",
    "import warnings\n",
    "from copy import deepcopy\n",
    "from functools import wraps\n",
    "from time import perf_counter\n",
    "from typing import Tuple, List, Dict, Optional, Union, Any, Callable\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import torch"
   ],
   "metadata": {
    "id": "e5-peUYjF-Rb"
   },
   "execution_count": 1,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Utilitary functions"
   ],
   "metadata": {
    "id": "PCqn3WDZIn_Q"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "def timeit(func: Callable[..., Any]) -> Callable[..., Any]:\n",
    "    \"\"\"\n",
    "    Decorator for timing function execution time.\n",
    "\n",
    "    Args:\n",
    "        func: The function to time.\n",
    "\n",
    "    Returns:\n",
    "        The wrapped function.\n",
    "    \"\"\"\n",
    "\n",
    "    @wraps(func)\n",
    "    def timeit_wrapper(*args, **kwargs):\n",
    "        start_time = perf_counter()\n",
    "        result = func(*args, **kwargs)\n",
    "        end_time = perf_counter()\n",
    "        total_time = end_time - start_time\n",
    "        print(f\"Function {func.__name__} took {total_time:.2f} seconds\")\n",
    "        return result\n",
    "\n",
    "    return timeit_wrapper\n",
    "\n",
    "\n",
    "def return_runtime(func: Callable[..., Any]) -> Callable[..., Tuple[float, ...]]:\n",
    "    \"\"\"\n",
    "    Decorator that adds the execution time to the return values of the function.\n",
    "    Unfortunately this decorator does not preserve the typing of the inner function.\n",
    "\n",
    "    Args:\n",
    "        func: The function to time.\n",
    "\n",
    "    Returns:\n",
    "        The wrapped function.\n",
    "    \"\"\"\n",
    "\n",
    "    @wraps(func)\n",
    "    def timeit_wrapper(*args, **kwargs):\n",
    "        start_time = perf_counter()\n",
    "        result = func(*args, **kwargs)\n",
    "        end_time = perf_counter()\n",
    "        total_time = end_time - start_time\n",
    "        return total_time, result\n",
    "\n",
    "    return timeit_wrapper\n",
    "\n",
    "\n",
    "def checkpoint(time_ref: float = perf_counter()) -> Callable[..., None]:\n",
    "    \"\"\"\n",
    "    Closure that stores a time checkpoint that is updated at every call.\n",
    "    Each call prints the time elapsed since the last checkpoint with a custom message.\n",
    "\n",
    "    Args:\n",
    "        time_ref: The time reference to start from. By default, the time of the call will be taken.\n",
    "\n",
    "    Returns:\n",
    "        The closure.\n",
    "    \"\"\"\n",
    "\n",
    "    def _closure(message: str = \"\") -> None:\n",
    "        \"\"\"\n",
    "        Prints the time elapsed since the previous call.\n",
    "\n",
    "        Args:\n",
    "            message: Custom message to print. The overall result will be: 'message: time_elapsed'.\n",
    "        \"\"\"\n",
    "        nonlocal time_ref\n",
    "        current_time = perf_counter()\n",
    "        if message != \"\":\n",
    "            print(f\"{message}: {current_time - time_ref:.4f}\")\n",
    "        time_ref = current_time\n",
    "\n",
    "    return _closure\n"
   ],
   "metadata": {
    "id": "6VVNleRhGVeN"
   },
   "execution_count": 2,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Data generation"
   ],
   "metadata": {
    "id": "7ItPq1z_IqgM"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "def create_path_graph(graph_size: int) -> nx.DiGraph:\n",
    "    \"\"\"\n",
    "    Creates a path graph (linear graph).\n",
    "    \"\"\"\n",
    "    return nx.path_graph(graph_size).to_directed()\n",
    "\n",
    "\n",
    "def create_cycle_graph(graph_size: int) -> nx.DiGraph:\n",
    "    \"\"\"\n",
    "    Creates a cycle graph (circular graph).\n",
    "    \"\"\"\n",
    "    return nx.cycle_graph(graph_size).to_directed()\n",
    "\n",
    "\n",
    "def create_wheel_graph(graph_size: int) -> nx.DiGraph:\n",
    "    \"\"\"\n",
    "    Creates a wheel graph (see Networkx's documentation).\n",
    "    \"\"\"\n",
    "    return nx.wheel_graph(graph_size).to_directed()\n",
    "\n",
    "\n",
    "def create_complete_graph(graph_size: int) -> nx.DiGraph:\n",
    "    \"\"\"\n",
    "    Creates a complete graph.\n",
    "    \"\"\"\n",
    "    return nx.complete_graph(graph_size).to_directed()\n",
    "\n",
    "\n",
    "def create_watts_strogatz_graph(graph_size: int) -> nx.DiGraph:\n",
    "    \"\"\"\n",
    "    Creates a connected graph using the Watts–Strogatz random graph generation model.\n",
    "    \"\"\"\n",
    "    return nx.connected_watts_strogatz_graph(graph_size, 3, 0.4).to_directed()\n",
    "\n",
    "\n",
    "def create_gnp_graph(graph_size: int) -> nx.DiGraph:\n",
    "    \"\"\"\n",
    "    Creates a connected graph using the Erdős–Rényi random graph generation model.\n",
    "    The loop looks ugly but something similar is actually performed in nx.connected_watts_strogatz_graph.\n",
    "    \"\"\"\n",
    "    n_attempts = 100\n",
    "    for i in range(n_attempts):\n",
    "        # for p > (1 + eps) ln(n) / n, the Erdős–Rényi graph should be connected almost surely\n",
    "        gnp_graph = nx.gnp_random_graph(graph_size, 2 * np.log(graph_size) / graph_size)\n",
    "        if nx.is_connected(gnp_graph):\n",
    "            print(\n",
    "                f\"Sparsity of the graph: {gnp_graph.size() / len(gnp_graph) ** 2 * 100:.2f}%.\"\n",
    "            )\n",
    "            return gnp_graph.to_directed()\n",
    "\n",
    "\n",
    "def create_bipartite_graph(graph_size: int) -> nx.DiGraph:\n",
    "    \"\"\"\n",
    "    Creates a connected bipartite graph using the Erdős–Rényi random graph generation model.\n",
    "    The loop looks ugly but something similar is actually performed in nx.connected_watts_strogatz_graph.\n",
    "    \"\"\"\n",
    "    n_attempts = 100\n",
    "    for i in range(n_attempts):\n",
    "        # for p > (1 + eps) ln(n) / n, the Erdős–Rényi graph should be connected almost surely\n",
    "        bipartite_graph = nx.bipartite.random_graph(\n",
    "            graph_size // 2, graph_size // 2, 2 * np.log(graph_size) / graph_size\n",
    "        )\n",
    "        if nx.is_connected(bipartite_graph):\n",
    "            print(\n",
    "                f\"Sparsity of the graph: {bipartite_graph.size() / len(bipartite_graph) ** 2 * 100:.2f}%.\"\n",
    "            )\n",
    "            return bipartite_graph.to_directed()\n",
    "\n",
    "\n",
    "def create_graph(graph_size: int, graph_type: str) -> nx.DiGraph():\n",
    "    \"\"\"\n",
    "    Creates a graph using one of the functions above depending on the input graph type.\n",
    "    \"\"\"\n",
    "    return (\n",
    "        create_bipartite_graph(graph_size)\n",
    "        if graph_type == \"bipartite\"\n",
    "        else create_cycle_graph(graph_size)\n",
    "        if graph_type == \"cycle\"\n",
    "        else create_path_graph(graph_size)\n",
    "        if graph_type == \"path\"\n",
    "        else create_complete_graph(graph_size)\n",
    "        if graph_type == \"complete\"\n",
    "        else create_gnp_graph(graph_size)\n",
    "    )"
   ],
   "metadata": {
    "id": "DL0nDZgdI5zc"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def add_random_weights(\n",
    "    graph: nx.Graph,\n",
    "    plot: bool = True,\n",
    "    positions: Optional[Dict[int, Tuple[float, float]]] = None,\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Adds random weights on the edges of the graph.\n",
    "    The weights are integers chosen randomly between 0 and 10 included.\n",
    "    \"\"\"\n",
    "    # noinspection PyArgumentList\n",
    "    for (_, __, w) in graph.edges(data=True):\n",
    "        w[\"weight\"] = random.randint(0, 10)\n",
    "\n",
    "    if plot:\n",
    "        print(\"Plotting the weights on each edge.\")\n",
    "        plt.figure()\n",
    "\n",
    "        positions = positions or nx.spectral_layout(graph)\n",
    "        edge_labels = {(u, v): weight for u, v, weight in graph.edges.data(\"weight\")}\n",
    "\n",
    "        nx.draw_networkx_edge_labels(graph, positions, edge_labels=edge_labels)\n",
    "        nx.draw(graph, positions, with_labels=True, node_size=500)\n",
    "\n",
    "        plt.show()"
   ],
   "metadata": {
    "id": "REMm-YlqGCX7"
   },
   "execution_count": 3,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def add_random_distributions(\n",
    "    graph: nx.Graph,\n",
    "    plot: bool = True,\n",
    "    positions: Optional[Dict[int, Tuple[float, float]]] = None,\n",
    "    distribution: str = \"dirichlet\",\n",
    "    nonzero_ratio: float = 1.0,\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Adds two random distributions on the nodes of the graph.\n",
    "    The distributions are added as node attributes (rho_0 and rho_1).\n",
    "    They are sampled using a Dirichlet distribution.\n",
    "    \"\"\"\n",
    "    n_nonzero = int(nonzero_ratio * len(graph))\n",
    "    # sampling the distributions using Dirichlet distributions (no need to divide by the sum)\n",
    "    if distribution == \"dirichlet\":\n",
    "        rho_0 = np.random.dirichlet(np.ones(n_nonzero), size=1)[0]\n",
    "        rho_1 = np.random.dirichlet(np.ones(n_nonzero), size=1)[0]\n",
    "    else:\n",
    "        rho_0 = np.random.random(n_nonzero)\n",
    "        rho_0 = rho_0 / np.sum(rho_0)\n",
    "        rho_1 = np.random.random(n_nonzero)\n",
    "        rho_1 = rho_1 / np.sum(rho_1)\n",
    "\n",
    "    nonzero_indexes = np.random.choice(len(graph), size=n_nonzero, replace=False)\n",
    "    j = 0\n",
    "    # noinspection PyArgumentList\n",
    "    for i, (_, w) in enumerate(graph.nodes(data=True)):\n",
    "        if i in nonzero_indexes:\n",
    "            w[\"rho_0\"] = rho_0[j]\n",
    "            w[\"rho_1\"] = rho_1[j]\n",
    "            j += 1\n",
    "        else:\n",
    "            w[\"rho_0\"] = 0.0\n",
    "            w[\"rho_1\"] = 0.0\n",
    "\n",
    "    if plot:\n",
    "        print(\"Plotting the two distributions on each node.\")\n",
    "        positions = positions or nx.spectral_layout(graph)\n",
    "        plt.figure(figsize=(14, 7))\n",
    "\n",
    "        ax1 = plt.subplot(121)\n",
    "        distribution = {\n",
    "            node: round(graph.nodes[node][\"rho_0\"], 2) for node in graph.nodes()\n",
    "        }\n",
    "        nx.draw_networkx_labels(graph, positions, labels=distribution, font_size=10)\n",
    "        nx.draw(\n",
    "            graph,\n",
    "            positions,\n",
    "            node_color=list(distribution.values()),\n",
    "            node_size=800,\n",
    "            ax=ax1,\n",
    "        )\n",
    "\n",
    "        ax2 = plt.subplot(122)\n",
    "        distribution = {\n",
    "            node: round(graph.nodes[node][\"rho_1\"], 2) for node in graph.nodes()\n",
    "        }\n",
    "        nx.draw_networkx_labels(graph, positions, labels=distribution, font_size=10)\n",
    "        nx.draw(\n",
    "            graph,\n",
    "            positions,\n",
    "            node_color=list(distribution.values()),\n",
    "            node_size=800,\n",
    "            ax=ax2,\n",
    "        )\n",
    "\n",
    "        plt.show()"
   ],
   "metadata": {
    "id": "nfYLCYj7Jq0R"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def plot_transportation_plan(\n",
    "    graph: nx.Graph, positions: Dict[int, Tuple[float, float]]\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Plots a graph with the associated transportation plan.\n",
    "\n",
    "    Args:\n",
    "        graph: networkx graph whose nodes have attributes 'rho_0' and 'rho_1' for the distributions\n",
    "            and attribute 'ot' on the edges for the value of the transportation plan.\n",
    "        positions: positions of each node.\n",
    "    \"\"\"\n",
    "    plt.figure()\n",
    "    edge_labels = {(u, v): round(ot, 3) for u, v, ot in graph.edges.data(\"ot\") if ot}\n",
    "    nx.draw_networkx_edge_labels(graph, positions, edge_labels=edge_labels)\n",
    "    nx.draw(graph, positions, with_labels=True, node_size=200, arrowsize=15)\n",
    "\n",
    "    plt.show()"
   ],
   "metadata": {
    "id": "BD7v_A-jJtI8"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Graph manipulation"
   ],
   "metadata": {
    "id": "fOe41izNIxeB"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "def compute_cost_matrix(graph: nx.Graph) -> Tuple[np.ndarray, List[List[List[int]]]]:\n",
    "    \"\"\"\n",
    "    Computes the cost matrix on a graph.\n",
    "    \"\"\"\n",
    "    n_nodes = len(graph)\n",
    "    cost_matrix = np.zeros((n_nodes, n_nodes))\n",
    "    shortest_paths = [[[] for _ in range(n_nodes)] for _ in range(n_nodes)]\n",
    "\n",
    "    # using networkx built-in shortest path (dijkstra algorithm)\n",
    "    for origin, path_lengths in dict(nx.all_pairs_dijkstra(graph)).items():\n",
    "        for destination, length in path_lengths[0].items():\n",
    "            cost_matrix[origin, destination] = length\n",
    "        for destination, path in path_lengths[1].items():\n",
    "            shortest_paths[origin][destination] = path\n",
    "\n",
    "    return cost_matrix, shortest_paths"
   ],
   "metadata": {
    "id": "DsZM42aWEKtY"
   },
   "execution_count": 4,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def collect_graph(\n",
    "    graph: nx.Graph,\n",
    "    transportation_plan: np.ndarray,\n",
    "    shortest_paths: List[List[List[int]]],\n",
    ") -> nx.Graph:\n",
    "    \"\"\"\n",
    "    Constructs a graph obtained by adding the values of a transportation plan between couples of nodes\n",
    "    on all the edges that form the path between the two nodes.\n",
    "    \"\"\"\n",
    "    collected_graph = deepcopy(graph)\n",
    "    nx.set_edge_attributes(collected_graph, 0., \"ot\")\n",
    "    for origin, row in enumerate(transportation_plan):\n",
    "        for destination, value in enumerate(row):\n",
    "            if value and value > 1e-6:\n",
    "                u = origin\n",
    "                for v in shortest_paths[origin][destination][1:]:\n",
    "                    collected_graph.edges[u, v][\"ot\"] += value\n",
    "                    u = v\n",
    "\n",
    "    return collected_graph"
   ],
   "metadata": {
    "id": "mgRXiMCyJvGj"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Sinkhorn algorithm using PyTorch"
   ],
   "metadata": {
    "id": "04p_E3z1Iz5f"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Running Sinkhorn on {device}.\")"
   ],
   "metadata": {
    "id": "WH94wrymJwt3"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def after_sinkhorn(\n",
    "    transportation_plan: np.ndarray,\n",
    "    graph: nx.Graph,\n",
    "    shortest_paths: List[List[List[int]]],\n",
    "    cost_matrix: np.ndarray,\n",
    "    f: np.ndarray,\n",
    "    verbose: bool,\n",
    ") -> Tuple[float, float, np.ndarray, float, nx.Graph]:\n",
    "    if verbose:\n",
    "        nonzero = np.count_nonzero(transportation_plan)\n",
    "        print(\n",
    "            f\"Optimal transportation plan (number of nonzero: {nonzero} / {transportation_plan.size}):\"\n",
    "        )\n",
    "        print(np.round(transportation_plan, 2))\n",
    "\n",
    "    # creating a copy of the graph that will only have the edges where there is a movement of mass\n",
    "    uncollected_graph = nx.create_empty_copy(graph)\n",
    "    # adding an attribute that will yield the value of the transportation plan\n",
    "    uncollected_graph.add_edges_from(\n",
    "        [\n",
    "            (origin, destination, {\"ot\": value})\n",
    "            for origin, row in enumerate(transportation_plan)\n",
    "            for destination, value in enumerate(row)\n",
    "            if value > 1e-3\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # adding the values of the ot on the initial graph by putting back the plan on the actual edges\n",
    "    collected_graph = collect_graph(graph, transportation_plan, shortest_paths)\n",
    "\n",
    "    flow = np.array(list(nx.get_edge_attributes(collected_graph, \"ot\").values()))\n",
    "    cost = float(np.sum(cost_matrix * transportation_plan))\n",
    "    quadratic_term = float(np.sum(np.square(flow)))\n",
    "    err = np.linalg.norm(nx.incidence_matrix(graph, oriented=True).toarray() @ flow - f)\n",
    "\n",
    "    if verbose:\n",
    "        nonzero = np.count_nonzero(flow)\n",
    "        print(f\"Optimal flow (number of nonzero: {nonzero} / {graph.size()}):\")\n",
    "        print(np.round(flow, 2))\n",
    "\n",
    "    return cost, quadratic_term, flow, err, collected_graph"
   ],
   "metadata": {
    "id": "GZSjbPLBJylp"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Standard Sinkhorn"
   ],
   "metadata": {
    "id": "BfBs5YABJ28Q"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Running Sinkhorn on cuda:0.\n"
     ]
    }
   ],
   "source": [
    "def sinkhorn(\n",
    "    graph: nx.Graph, alpha: float, verbose: bool = True\n",
    ") -> Tuple[float, float, np.ndarray, float, nx.Graph]:\n",
    "\n",
    "    epsilon = alpha\n",
    "\n",
    "    n_nodes = len(graph)\n",
    "    rho_0 = np.array(list(nx.get_node_attributes(graph, \"rho_0\").values()))\n",
    "    rho_1 = np.array(list(nx.get_node_attributes(graph, \"rho_1\").values()))\n",
    "    cost_matrix, shortest_paths = compute_cost_matrix(graph)\n",
    "\n",
    "    K = np.exp(-(cost_matrix**2) / epsilon)\n",
    "    u = torch.ones(n_nodes)\n",
    "    v = torch.ones(n_nodes)\n",
    "\n",
    "    K1 = torch.from_numpy(K).type(torch.FloatTensor)\n",
    "    a1 = torch.from_numpy(rho_0).type(torch.FloatTensor)\n",
    "    b1 = torch.from_numpy(rho_1).type(torch.FloatTensor)\n",
    "\n",
    "    K1 = K1.to(device)\n",
    "    u = u.to(device)\n",
    "    v = v.to(device)\n",
    "    a1 = a1.to(device)\n",
    "    b1 = b1.to(device)\n",
    "\n",
    "    n_iter = 4000\n",
    "    for i in range(n_iter):\n",
    "        u = a1 / (K1 * v[None, :]).sum(1)\n",
    "        v = b1 / (K1 * u[:, None]).sum(0)\n",
    "\n",
    "    transportation_plan = np.diag(u.cpu()) @ K @ np.diag(v.cpu())\n",
    "\n",
    "    return after_sinkhorn(\n",
    "        transportation_plan, graph, shortest_paths, cost_matrix, rho_1 - rho_0, verbose\n",
    "    )"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WVTJeYprDnew",
    "outputId": "93a75d4b-da78-43e0-dc86-2ee86739322e"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Log-domain Sinkhorn\n",
    "\n",
    "Implementation based on a log-sum-exp trick to improve numerical stability."
   ],
   "metadata": {
    "id": "0lIT5cB4J6Lj"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "def stable_sinkhorn(\n",
    "    graph: nx.Graph, alpha: float, verbose: bool = True\n",
    ") -> Tuple[float, float, np.ndarray, float, nx.Graph]:\n",
    "\n",
    "    epsilon = alpha\n",
    "\n",
    "    n_nodes = len(graph)\n",
    "    rho_0 = np.array(list(nx.get_node_attributes(graph, \"rho_0\").values()))\n",
    "    rho_1 = np.array(list(nx.get_node_attributes(graph, \"rho_1\").values()))\n",
    "    cost_matrix, shortest_paths = compute_cost_matrix(graph)\n",
    "\n",
    "    C = torch.autograd.Variable(torch.from_numpy(cost_matrix).to(device))\n",
    "\n",
    "    def modified_cost(u_val, v_val):\n",
    "        return (-C + u_val.unsqueeze(1) + v_val.unsqueeze(0)) / epsilon\n",
    "\n",
    "    def stable_lse(A):\n",
    "        # adding 10^-6 to prevent NaN\n",
    "        return torch.log(\n",
    "            torch.exp(A - torch.max(A)).sum(1, keepdim=True) + 1e-6\n",
    "        ) + torch.max(A)\n",
    "\n",
    "    u = torch.ones(n_nodes)\n",
    "    v = torch.ones(n_nodes)\n",
    "\n",
    "    a1 = torch.from_numpy(rho_0).type(torch.FloatTensor)\n",
    "    b1 = torch.from_numpy(rho_1).type(torch.FloatTensor)\n",
    "\n",
    "    u = u.to(device)\n",
    "    v = v.to(device)\n",
    "    a1 = a1.to(device)\n",
    "    b1 = b1.to(device)\n",
    "\n",
    "    n_iter = 10000\n",
    "    for i in range(n_iter):\n",
    "        u = epsilon * (torch.log(a1) - stable_lse(modified_cost(u, v)).squeeze()) + u\n",
    "        v = (\n",
    "            epsilon * (torch.log(b1) - stable_lse(modified_cost(u, v).t()).squeeze())\n",
    "            + v\n",
    "        )\n",
    "\n",
    "    transportation_plan = torch.exp(modified_cost(u, v)).cpu()\n",
    "\n",
    "    return after_sinkhorn(\n",
    "        transportation_plan.numpy(),\n",
    "        graph,\n",
    "        shortest_paths,\n",
    "        cost_matrix,\n",
    "        rho_1 - rho_0,\n",
    "        verbose,\n",
    "    )"
   ],
   "metadata": {
    "id": "2zSqPuiTJ13k"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Pipeline"
   ],
   "metadata": {
    "id": "7SvK-uR6I8ZP"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "choose_algo = {\n",
    "    \"sinkhorn\": sinkhorn,\n",
    "    \"stable_sinkhorn\": stable_sinkhorn,\n",
    "}"
   ],
   "metadata": {
    "id": "0pfh3hrIKHJf"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def update_records(\n",
    "    records: Dict[str, Union[float, int, List[np.ndarray]]],\n",
    "    dist: float,\n",
    "    quadratic_term: float,\n",
    "    error: float,\n",
    "    solution: np.ndarray,\n",
    "    runtime: float,\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Adds a record to a dict of records taking into account unsuccessful runs.\n",
    "    \"\"\"\n",
    "    if dist < 1e-12 or dist == np.inf or np.isnan(dist):\n",
    "        records[\"fails\"] += 1\n",
    "    else:\n",
    "        records[\"cost\"] += dist\n",
    "        records[\"quadratic_term\"] += quadratic_term\n",
    "        records[\"error\"] += error\n",
    "    records[\"runtime\"] += runtime\n",
    "    records[\"solutions\"].append(solution)\n",
    "\n",
    "\n",
    "def average_records(\n",
    "    records: Dict[str, Union[float, int, List[np.ndarray]]],\n",
    "    n_runs_per_graph: int,\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Averages the values of the costs and quadratic terms measured by dividing by the number of successful runs.\n",
    "    Also updates the average runtime.\n",
    "    \"\"\"\n",
    "    n_successful_runs = n_runs_per_graph > records[\"fails\"]\n",
    "\n",
    "    if n_successful_runs > 0:\n",
    "        records[\"cost\"] /= n_successful_runs\n",
    "        records[\"quadratic_term\"] /= n_successful_runs\n",
    "        records[\"error\"] /= n_successful_runs\n",
    "\n",
    "    records[\"runtime\"] /= n_runs_per_graph"
   ],
   "metadata": {
    "id": "mCiX1XarKJQI"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "@timeit\n",
    "def full_pipeline(\n",
    "    graph: nx.Graph, n_runs_per_graph: int, nonzero_ratio: float, *args, **kwargs\n",
    ") -> Dict[str, Union[float, int, List[np.ndarray]]]:\n",
    "    results = {\n",
    "        algo: {\n",
    "            \"cost\": 0.0,\n",
    "            \"quadratic_term\": 0.0,\n",
    "            \"error\": 0.0,\n",
    "            \"runtime\": 0,\n",
    "            \"fails\": 0,\n",
    "            \"solutions\": [],\n",
    "        }\n",
    "        for algo in choose_algo\n",
    "    }\n",
    "\n",
    "    for n_run in range(n_runs_per_graph):\n",
    "        graph_copy = deepcopy(graph)\n",
    "        add_random_distributions(graph_copy, plot=False, nonzero_ratio=nonzero_ratio)\n",
    "\n",
    "        for algo in [\"sinkhorn\", \"stable_sinkhorn\"]:\n",
    "            print(\n",
    "                f\"-- Run number {n_run:>{len(str(n_runs_per_graph))}} of algo {algo:<15}:\",\n",
    "                end=\" \",\n",
    "            )\n",
    "            runtime, (dist, quad_term, sol, err, sol_graph) = return_runtime(\n",
    "                choose_algo[algo]\n",
    "            )(graph_copy, *args, **kwargs)\n",
    "            print(\n",
    "                f\"cost: {dist:.2f}, quadratic term: {quad_term:.2f}, err: {err:.2f}, runtime: {runtime:.2f} s\"\n",
    "            )\n",
    "            update_records(results[algo], dist, quad_term, err, sol, runtime)\n",
    "        print(\"\")\n",
    "\n",
    "    for record in results.values():\n",
    "        average_records(record, n_runs_per_graph)\n",
    "\n",
    "    return results"
   ],
   "metadata": {
    "id": "GD0KiSwBFCMj"
   },
   "execution_count": 6,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Experiment"
   ],
   "metadata": {
    "id": "qlwEzfEXKLSX"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "graph_sizes = [50, 100, 500, 1000]\n",
    "graph_type = \"bipartite\"\n",
    "alphas = [10, 5, 1, 0.1, 1e-2, 1e-3, 1e-4, 1e-5]\n",
    "n_runs_per_graph = 10\n",
    "proportion_of_sink = 0.1\n",
    "\n",
    "results = {graph_size: {} for graph_size in graph_sizes}\n",
    "for graph_size in graph_sizes:\n",
    "    graph = create_graph(graph_size, graph_type)\n",
    "    add_random_weights(graph, plot=False)\n",
    "\n",
    "    for alpha in alphas:\n",
    "        print(f\"\\nGraph size: {graph_size}, alpha: {alpha}\")\n",
    "        results[graph_size][alpha] = full_pipeline(\n",
    "            graph,\n",
    "            n_runs_per_graph,\n",
    "            proportion_of_sink,\n",
    "            alpha=alpha,\n",
    "            verbose=False,\n",
    "        )\n",
    "\n",
    "# removing unserializable np.ndarray\n",
    "for graph_size in results.values():\n",
    "    for alpha in graph_size.values():\n",
    "        for algo in alpha.values():\n",
    "            algo.pop(\"solutions\")\n",
    "\n",
    "print(json.dumps(results, indent=2))"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "q666A2PpF0gO",
    "outputId": "c5b17efd-e8be-4693-905e-5835f18fe9ca",
    "pycharm": {
     "is_executing": true
    }
   },
   "execution_count": null,
   "outputs": []
  }
 ]
}
